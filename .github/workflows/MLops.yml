name: MLops
on: 
  push:
    branches: [ "new-example-2" ]
  workflow_dispatch: 
jobs:
  run:
    runs-on: [self-hosted, cirun.gpu]
    container:
      image: ghcr.io/iterative/cml:0-dvc2-base1-gpu
      options: --gpus all
    steps:
      - uses: actions/checkout@v3
      - name: Get Free Memory
        run: free -h
      - name: Run NVIDIA-SMI
        run: |
          echo Running nvidia-smi
          nvidia-smi
      - name: Dependency Install
        run: pip install -r requirements.txt
      - name: MLops
        env:
          repo_token: ${{ secrets.GITHUB_TOKEN }}
        run: |
          
          # Your ML workflow goes here
          python finalModel.py